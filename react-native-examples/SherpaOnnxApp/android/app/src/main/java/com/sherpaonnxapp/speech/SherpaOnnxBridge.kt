package com.sherpaonnxapp.speech

import android.content.res.AssetManager
import android.util.Log
import android.media.AudioRecord
import android.media.MediaRecorder
import android.media.AudioFormat
import com.k2fsa.sherpa.onnx.*
import java.util.concurrent.atomic.AtomicBoolean
import kotlinx.coroutines.*
import kotlinx.coroutines.channels.Channel
import kotlinx.coroutines.channels.Channel.Factory.UNLIMITED
import java.io.File
import java.io.FileOutputStream
import java.io.RandomAccessFile
import java.text.SimpleDateFormat
import java.util.*

// ğŸš€ å®Œå…¨å¤åˆ»åç¼–è¯‘APKçš„åŒåç¨‹æ¶æ„ + å½•éŸ³æ–‡ä»¶ä¿å­˜
class SherpaOnnxBridge(private val assetManager: AssetManager) {
    private var offlineRecognizer: OfflineRecognizer? = null
    private var vad: Vad? = null
    private val TAG = "SherpaOnnxBridge"
    
    // ğŸ¯ åç¼–è¯‘APKçš„æ ¸å¿ƒå‚æ•°
    private val sampleRate = 16000
    private val windowSize = 6400 // 0.4ç§’çª—å£ï¼ˆå®Œå…¨å¤åˆ»ï¼‰
    private val chunkSize = 1600   // 0.1ç§’éŸ³é¢‘å—ï¼ˆå®Œå…¨å¤åˆ»ï¼‰
    
    // ğŸ¯ åŒåç¨‹é€šä¿¡Channelï¼ˆå¤åˆ»åç¼–è¯‘APKï¼‰
    private val samplesChannel = Channel<FloatArray>(UNLIMITED)
    
    // ğŸ¯ åç¼–è¯‘APKçš„çŠ¶æ€å˜é‡ï¼ˆå®Œå…¨å¯¹åº”ï¼‰
    private val audioBuffer = mutableListOf<Float>()
    private var lastText = ""
    private var offset = 0
    private var isSpeechStarted = false
    private var startTime = 0L
    private var added = false
    
    // ğŸ¯ åŸç”ŸAudioRecordï¼ˆå¤åˆ»åç¼–è¯‘APKï¼‰
    private var audioRecord: AudioRecord? = null
    private val isRecording = AtomicBoolean(false)
    private var recordingJob: Job? = null
    private var processingJob: Job? = null
    
    // ğŸ¯ ç»“æœç®¡ç† - ä¼˜åŒ–æ˜¾ç¤ºé€»è¾‘
    private val resultList = mutableListOf<String>()
    private var currentPartialText = ""
    private var lastStableText = ""
    private var stableCounter = 0
    private var silentCounter = 0        // ğŸ”§ æ–°å¢ï¼šé™éŸ³è®¡æ•°å™¨
    private val maxSilentFrames = 10     // ğŸ”§ æ–°å¢ï¼šæœ€å¤§é™éŸ³å¸§æ•°
    private var onResultCallback: ((String) -> Unit)? = null
    
    // ğŸµ å½•éŸ³æ–‡ä»¶ä¿å­˜åŠŸèƒ½
    private var audioFileWriter: FileOutputStream? = null
    private var currentAudioFile: File? = null
    private var recordedAudioData = mutableListOf<Short>()

    companion object {
        init {
            try {
                System.loadLibrary("sherpa-onnx-jni")
                Log.i("SherpaOnnxBridge", "Successfully loaded sherpa-onnx-jni library")
            } catch (e: UnsatisfiedLinkError) {
                Log.e("SherpaOnnxBridge", "Failed to load sherpa-onnx-jni library: ${e.message}")
            }
        }
    }

    fun initialize(): Boolean {
        return try {
            Log.i(TAG, "ğŸš€ Initializing SenseVoice + VAD recognizer (APK-style)")
            
            // åˆå§‹åŒ–åŸç”ŸAudioRecordï¼ˆå¤åˆ»åç¼–è¯‘APKï¼‰
            initializeAudioRecord()
            
            // åˆå§‹åŒ–VAD
            vad = createVAD()
            
            // åˆå§‹åŒ–SenseVoiceè¯†åˆ«å™¨
            offlineRecognizer = createSenseVoiceRecognizer()
            
            Log.i(TAG, "âœ… SenseVoice + VAD recognizer initialized successfully")
            true
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Failed to initialize recognizer: ${e.message}")
            e.printStackTrace()
            false
        }
    }

    // ğŸ¯ å¤åˆ»åç¼–è¯‘APKçš„AudioRecordåˆå§‹åŒ–
    private fun initializeAudioRecord() {
        val channelConfig = AudioFormat.CHANNEL_IN_MONO
        val audioFormat = AudioFormat.ENCODING_PCM_16BIT
        val minBufferSize = AudioRecord.getMinBufferSize(sampleRate, channelConfig, audioFormat)
        val bufferSize = minBufferSize.coerceAtLeast(chunkSize * 2)
        
        audioRecord = AudioRecord(
            MediaRecorder.AudioSource.MIC,
            sampleRate,
            channelConfig,
            audioFormat,
            bufferSize
        )
        
        Log.i(TAG, "ğŸ™ï¸ AudioRecord initialized: bufferSize=$bufferSize, chunkSize=$chunkSize")
    }

    private fun createVAD(): Vad {
        val sileroVadConfig = SileroVadModelConfig(
            model = "silero_vad.onnx",
            threshold = 0.45f,
            minSilenceDuration = 0.5f,
            minSpeechDuration = 0.25f,
            maxSpeechDuration = 8.0f,
            windowSize = 512
        )
        
        val vadConfig = VadModelConfig(
            sileroVadModelConfig = sileroVadConfig,
            sampleRate = sampleRate,
            numThreads = 1,
            provider = "cpu",
            debug = false
        )
        
        return Vad(assetManager, vadConfig)
    }

    private fun createSenseVoiceRecognizer(): OfflineRecognizer {
        val senseVoiceConfig = OfflineSenseVoiceModelConfig(
            model = "models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx",
            language = "",  // ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹è¯­è¨€
            useInverseTextNormalization = true
        )
        
        val modelConfig = OfflineModelConfig(
            senseVoice = senseVoiceConfig,
            tokens = "models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt",
            modelType = "sense_voice",
            numThreads = 2,  // ğŸ¯ ä¸¥æ ¼å¤åˆ»ï¼šå¼ºåˆ¶è®¾ç½®ä¸º2çº¿ç¨‹
            debug = false,
            provider = "cpu"
        )
        
        val recognizerConfig = OfflineRecognizerConfig(
            featConfig = getFeatureConfig(sampleRate = sampleRate, featureDim = 80),
            modelConfig = modelConfig,
            decodingMethod = "greedy_search",
            maxActivePaths = 4
        )
        
        return OfflineRecognizer(assetManager, recognizerConfig)
    }

    // ğŸµ åˆå§‹åŒ–å½•éŸ³æ–‡ä»¶
    private fun initializeAudioFile(): File? {
        return try {
            val timestamp = SimpleDateFormat("yyyyMMdd_HHmmss", Locale.getDefault()).format(Date())
            val fileName = "recording_$timestamp.wav"
            
            // ä½¿ç”¨å¤–éƒ¨å­˜å‚¨çš„ Downloads ç›®å½•
            val downloadsDir = File("/storage/emulated/0/Download")
            if (!downloadsDir.exists()) {
                downloadsDir.mkdirs()
            }
            
            val audioFile = File(downloadsDir, fileName)
            
            // åˆ›å»º WAV æ–‡ä»¶å¤´ï¼ˆ44å­—èŠ‚ï¼‰
            val fileOutputStream = FileOutputStream(audioFile)
            writeWavHeader(fileOutputStream, 0) // å…ˆå†™ä¸€ä¸ªå ä½çš„header
            
            audioFileWriter = fileOutputStream
            currentAudioFile = audioFile
            recordedAudioData.clear()
            
            Log.i(TAG, "ğŸµ Audio file initialized: ${audioFile.absolutePath}")
            audioFile
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Failed to initialize audio file: ${e.message}")
            null
        }
    }

    // ğŸµ å†™å…¥WAVæ–‡ä»¶å¤´
    private fun writeWavHeader(fos: FileOutputStream, dataSize: Int) {
        val header = ByteArray(44)
        val fileSize = dataSize + 36
        
        // RIFF header
        "RIFF".toByteArray().copyInto(header, 0)
        intToByteArray(fileSize).copyInto(header, 4)
        "WAVE".toByteArray().copyInto(header, 8)
        
        // fmt chunk
        "fmt ".toByteArray().copyInto(header, 12)
        intToByteArray(16).copyInto(header, 16)  // fmt chunk size
        shortToByteArray(1).copyInto(header, 20) // PCM format
        shortToByteArray(1).copyInto(header, 22) // channels
        intToByteArray(sampleRate).copyInto(header, 24) // sample rate
        intToByteArray(sampleRate * 2).copyInto(header, 28) // byte rate
        shortToByteArray(2).copyInto(header, 32) // block align
        shortToByteArray(16).copyInto(header, 34) // bits per sample
        
        // data chunk
        "data".toByteArray().copyInto(header, 36)
        intToByteArray(dataSize).copyInto(header, 40)
        
        fos.write(header)
    }

    private fun intToByteArray(value: Int): ByteArray {
        return byteArrayOf(
            (value and 0xFF).toByte(),
            ((value shr 8) and 0xFF).toByte(),
            ((value shr 16) and 0xFF).toByte(),
            ((value shr 24) and 0xFF).toByte()
        )
    }

    private fun shortToByteArray(value: Int): ByteArray {
        return byteArrayOf(
            (value and 0xFF).toByte(),
            ((value shr 8) and 0xFF).toByte()
        )
    }

    // ğŸ¯ å¤åˆ»åç¼–è¯‘APKçš„åŒåç¨‹å¯åŠ¨
    fun startRecognition(): Boolean {
        return try {
            if (offlineRecognizer == null || vad == null || audioRecord == null) {
                initialize()
            }
            
            // ğŸ”§ å½»åº•é‡ç½®æ‰€æœ‰çŠ¶æ€ï¼Œç¡®ä¿å¹²å‡€å¼€å§‹
            audioBuffer.clear()
            resultList.clear()
            lastText = ""
            lastStableText = ""
            stableCounter = 0
            silentCounter = 0           // ğŸ”§ é‡ç½®é™éŸ³è®¡æ•°å™¨
            offset = 0
            isSpeechStarted = false
            startTime = System.currentTimeMillis()
            added = false
            currentPartialText = ""
            
            // ğŸ”§ ç«‹å³å‘é€ç©ºç»“æœï¼Œæ¸…ç©ºUIæ˜¾ç¤º
            onResultCallback?.invoke("")
            
            // ğŸµ åˆå§‹åŒ–å½•éŸ³æ–‡ä»¶
            initializeAudioFile()
            
            isRecording.set(true)
            
            // ğŸš€ å¯åŠ¨åŒåç¨‹ï¼ˆå®Œå…¨å¤åˆ»åç¼–è¯‘APKæ¶æ„ï¼‰
            startAnonymousClass1() // éŸ³é¢‘å½•åˆ¶åç¨‹
            startAnonymousClass2() // éŸ³é¢‘å¤„ç†åç¨‹
            
            Log.i(TAG, "ğŸ™ï¸ sherpa-onnx-sim-asr: Started dual-coroutine recording")
            true
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Failed to start recognition: ${e.message}")
            false
        }
    }

    // ğŸ¯ AnonymousClass1: éŸ³é¢‘å½•åˆ¶åç¨‹ï¼ˆå®Œå…¨å¤åˆ»åç¼–è¯‘APKï¼‰
    private fun startAnonymousClass1() {
        recordingJob = CoroutineScope(Dispatchers.IO).launch {
            Log.i(TAG, "ğŸ™ï¸ sherpa-onnx-sim-asr: processing samples")
            
            // å®Œå…¨å¤åˆ»åç¼–è¯‘APKï¼š16000 * 0.1 = 1600æ ·æœ¬
            val bufferSize = (sampleRate * 0.1).toInt()
            val shortBuffer = ShortArray(bufferSize)
            
            audioRecord?.startRecording()
            
            while (isRecording.get()) {
                val bytesRead = audioRecord?.read(shortBuffer, 0, shortBuffer.size) ?: -1
                
                if (bytesRead > 0) {
                    // ğŸµ ä¿å­˜å½•éŸ³æ•°æ®
                    recordedAudioData.addAll(shortBuffer.take(bytesRead))
                    
                    // ğŸ¯ å®Œå…¨å¤åˆ»åç¼–è¯‘APKçš„è½¬æ¢é€»è¾‘
                    val floatSamples = FloatArray(bytesRead)
                    for (i in 0 until bytesRead) {
                        val shortSample = shortBuffer[i]
                        floatSamples[i] = shortSample.toFloat() / 32768.0f // å¤åˆ»APKè½¬æ¢
                    }
                    
                    // é€šè¿‡Channelå‘é€ï¼ˆå¤åˆ»åç¼–è¯‘APKï¼‰
                    samplesChannel.trySend(floatSamples)
                }
            }
            
            // å‘é€ç©ºæ•°ç»„ç»“æŸä¿¡å·ï¼ˆå¤åˆ»åç¼–è¯‘APKï¼‰
            samplesChannel.trySend(FloatArray(0))
        }
    }

    // ğŸ¯ AnonymousClass2: éŸ³é¢‘å¤„ç†åç¨‹ï¼ˆå®Œå…¨å¤åˆ»åç¼–è¯‘APKï¼‰
    private fun startAnonymousClass2() {
        processingJob = CoroutineScope(Dispatchers.Default).launch {
            Log.i(TAG, "ğŸ”„ sherpa-onnx-sim-asr: å¯åŠ¨AnonymousClass2")
            
            // å¤åˆ»åç¼–è¯‘APKçš„å¾ªç¯å¤„ç†
            for (samples in samplesChannel) {
                if (samples.isEmpty()) break // ç»“æŸä¿¡å·
                
                // ğŸ¯ å®Œå…¨å¤åˆ»åç¼–è¯‘APKçš„å¤„ç†é€»è¾‘
                processAnonymousClass2Logic(samples)
            }
        }
    }

    // ğŸ¯ æ ¸å¿ƒï¼šAnonymousClass2çš„å¤„ç†é€»è¾‘ï¼ˆå®Œå…¨å¤åˆ»åç¼–è¯‘APKï¼‰
    private suspend fun processAnonymousClass2Logic(floatSamples: FloatArray) {
        try {
            audioBuffer.addAll(floatSamples.toList())
            
            // ğŸ”§ æ›´ä¸¥æ ¼çš„éŸ³é¢‘ä¿¡å·æ£€æµ‹
            val audioEnergy = floatSamples.sumOf { kotlin.math.abs(it.toDouble()) } / floatSamples.size
            val hasSignificantAudio = audioEnergy > 0.005 // æé«˜é˜ˆå€¼
            
            if (!hasSignificantAudio) {
                silentCounter++
                // ğŸ”§ é™éŸ³æ—¶ç«‹å³æ¸…é™¤å®æ—¶æ–‡æœ¬ï¼Œé¿å…è™šå‡è¯†åˆ«
                if (silentCounter > 3 && currentPartialText.isNotEmpty()) {
                    currentPartialText = ""
                    updateResults()
                    Log.d(TAG, "ğŸ”‡ Cleared partial text due to silence")
                }
                // ğŸ”§ é•¿æ—¶é—´é™éŸ³æ—¶ä¸è¿›è¡Œå®æ—¶è¯†åˆ«
                if (silentCounter > maxSilentFrames) {
                    return
                }
            } else {
                silentCounter = 0
                isSpeechStarted = true // æ ‡è®°å¼€å§‹æœ‰è¯­éŸ³è¾“å…¥
            }
            
            // ğŸ¯ VADå¤„ç† - ä¸»è¦ç”¨äºæ£€æµ‹å®Œæ•´è¯­éŸ³æ®µ
            if (audioBuffer.size >= chunkSize) {
                processVADWithBuffer()
            }
            
            // ğŸ¯ æ»‘åŠ¨çª—å£æœºåˆ¶ï¼ˆå¤åˆ»åç¼–è¯‘APKé€»è¾‘ï¼‰
            if (audioBuffer.size >= windowSize * 3) {
                val removeCount = audioBuffer.size - windowSize
                repeat(removeCount) { audioBuffer.removeAt(0) }
                offset += removeCount
            }
            
            // ğŸ”§ åªåœ¨ç¡®å®æœ‰è¯­éŸ³è¾“å…¥ä¸”éŸ³é¢‘èƒ½é‡è¶³å¤Ÿæ—¶æ‰è¿›è¡Œå®æ—¶è¯†åˆ«
            if (hasSignificantAudio && isSpeechStarted && audioBuffer.size >= windowSize && audioBuffer.size % 800 == 0) {
                performStableRealtimeRecognition()
            }
        } catch (e: Exception) {
            Log.e(TAG, "AnonymousClass2å¤„ç†é”™è¯¯: ${e.message}")
        }
    }

    private fun processVADWithBuffer() {
        try {
            val vadChunkSize = chunkSize
            if (audioBuffer.size >= vadChunkSize) {
                val vadData = FloatArray(vadChunkSize)
                val startIndex = kotlin.math.max(0, audioBuffer.size - vadChunkSize)
                
                for (i in 0 until vadChunkSize) {
                    vadData[i] = audioBuffer[startIndex + i]
                }
                
                vad?.acceptWaveform(vadData)
                
                // ğŸ¯ å¤„ç†VADæ£€æµ‹åˆ°çš„å®Œæ•´è¯­éŸ³æ®µ
                while (vad?.empty() == false) {
                    val speechSegment = vad?.front()
                    vad?.pop()
                    
                    if (speechSegment != null) {
                        processFinalSpeechSegment(speechSegment)
                    }
                }
            }
        } catch (e: Exception) {
            Log.e(TAG, "VAD processing error: ${e.message}")
        }
    }

    private fun processFinalSpeechSegment(speechSegment: SpeechSegment) {
        try {
            val stream = offlineRecognizer?.createStream()
            stream?.acceptWaveform(speechSegment.samples, sampleRate)
            
            offlineRecognizer?.decode(stream!!)
            val result = offlineRecognizer?.getResult(stream!!)
            val text = result?.text?.trim() ?: ""
            
            // ğŸ”§ åªæ·»åŠ æœ‰æ„ä¹‰çš„æ–‡æœ¬ï¼ˆé•¿åº¦>2ï¼Œä¸”ä¸æ˜¯å•ä¸ªå­—ç¬¦é‡å¤ï¼‰
            if (text.isNotEmpty() && text.length > 2 && !isRepeatedCharacter(text)) {
                resultList.add(text)
                currentPartialText = "" // æ¸…é™¤å®æ—¶æ–‡æœ¬
                updateResults()
                Log.i(TAG, "âœ… Speech segment recognized: $text")
            }
            
            stream?.release()
        } catch (e: Exception) {
            Log.e(TAG, "Error processing speech segment: ${e.message}")
        }
    }

    // ğŸ”§ æ£€æµ‹æ˜¯å¦ä¸ºé‡å¤å­—ç¬¦
    private fun isRepeatedCharacter(text: String): Boolean {
        if (text.length < 3) return false
        val firstChar = text[0]
        return text.all { it == firstChar || it == 'ã€‚' || it == 'ï¼Œ' }
    }

    private fun performStableRealtimeRecognition() {
        try {
            if (audioBuffer.size < windowSize) return
            
            val windowStart = kotlin.math.max(0, audioBuffer.size - windowSize)
            val windowAudio = FloatArray(windowSize)
            
            for (i in 0 until windowSize) {
                windowAudio[i] = audioBuffer[windowStart + i]
            }
            
            // ğŸ”§ æ£€æŸ¥éŸ³é¢‘çª—å£çš„éŸ³é¢‘èƒ½é‡ï¼Œé¿å…å¤„ç†é™éŸ³æ®µ
            val windowEnergy = windowAudio.sumOf { kotlin.math.abs(it.toDouble()) } / windowAudio.size
            if (windowEnergy < 0.003) {
                return // è·³è¿‡ä½èƒ½é‡éŸ³é¢‘æ®µ
            }
            
            val stream = offlineRecognizer?.createStream()
            stream?.acceptWaveform(windowAudio, sampleRate)
            
            offlineRecognizer?.decode(stream!!)
            val result = offlineRecognizer?.getResult(stream!!)
            val text = result?.text?.trim() ?: ""
            
            // ğŸ”§ æ›´ä¸¥æ ¼çš„æ–‡æœ¬è¿‡æ»¤ï¼šé¿å…å•è¯ã€é‡å¤å­—ç¬¦ã€è¿‡çŸ­æ–‡æœ¬
            if (isValidRecognitionText(text) && text != lastText) {
                // å–æ¶ˆç¨³å®šæ€§è¦æ±‚ï¼Œç«‹å³æ˜¾ç¤ºæœ‰æ•ˆè¯†åˆ«ç»“æœ
                lastText = text
                currentPartialText = text
                updateResults()
                Log.d(TAG, "ğŸ”Š ç«‹å³æ˜¾ç¤ºè¯†åˆ«ç»“æœ: $text")
            }
            
            stream?.release()
        } catch (e: Exception) {
            Log.e(TAG, "Error in realtime recognition: ${e.message}")
        }
    }
    
    // ğŸ”§ æ›´ä¸¥æ ¼çš„æ–‡æœ¬éªŒè¯
    private fun isValidRecognitionText(text: String): Boolean {
        if (text.isEmpty() || text.length < 3) return false
        if (isRepeatedCharacter(text)) return false
        
        // è¿‡æ»¤å¸¸è§çš„è™šå‡è¯†åˆ«ç»“æœ
        val invalidTexts = listOf("yeah", "uh", "um", "ah", "oh", "er", "å‘ƒ", "å—¯", "å•Š", "å“¦")
        if (invalidTexts.any { text.lowercase().contains(it) && text.length <= 6 }) {
            return false
        }
        
        // ç¡®ä¿åŒ…å«æœ‰æ„ä¹‰çš„å­—ç¬¦ï¼ˆä¸­æ–‡ã€è‹±æ–‡å•è¯ç­‰ï¼‰
        val hasMeaningfulContent = text.any { it.isLetter() || it in '\u4e00'..'\u9fff' }
        return hasMeaningfulContent
    }

    // ğŸ¯ æ›´æ–°ç»“æœæ˜¾ç¤ºï¼ˆå¤åˆ»åç¼–è¯‘APKæ ¼å¼ï¼‰
    private fun updateResults() {
        val displayText = StringBuilder()
        
        // æ·»åŠ å·²å®Œæˆçš„è¯†åˆ«ç»“æœ
        resultList.forEachIndexed { index, text ->
            displayText.append("$text")
//            if (index < resultList.size - 1) {
  //              displayText.append("\n")
    //        }
        }
        
        // ğŸ”§ åªåœ¨æœ‰æœ‰æ•ˆè¯†åˆ«ç»“æœæ—¶æ·»åŠ å½“å‰éƒ¨åˆ†è¯†åˆ«ç»“æœ
        if (currentPartialText.isNotEmpty() && isValidRecognitionText(currentPartialText)) {
        //    if (displayText.isNotEmpty()) {
         //       displayText.append("\n")
        //    }
            displayText.append("$currentPartialText")
        }
        
        // å›è°ƒæ›´æ–°UIï¼ˆæ¨¡æ‹Ÿåç¼–è¯‘APKçš„è‡ªåŠ¨æ»šåŠ¨æ•ˆæœï¼‰
        onResultCallback?.invoke(displayText.toString())
    }

    fun setResultCallback(callback: (String) -> Unit) {
        onResultCallback = callback
    }

    fun stopRecognition(): Boolean {
        return try {
            isRecording.set(false)
            
            // åœæ­¢å½•éŸ³
            audioRecord?.stop()
            
            // ğŸµ å®Œæˆå½•éŸ³æ–‡ä»¶å†™å…¥
            finalizeAudioFile()
            
            // å–æ¶ˆåç¨‹
            recordingJob?.cancel()
            processingJob?.cancel()
            
            Log.i(TAG, "ğŸ›‘ Recognition stopped")
            true
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Failed to stop recognition: ${e.message}")
            false
        }
    }

    // ğŸµ å®ŒæˆéŸ³é¢‘æ–‡ä»¶å†™å…¥
    private fun finalizeAudioFile() {
        try {
            if (audioFileWriter != null && currentAudioFile != null && recordedAudioData.isNotEmpty()) {
                // å†™å…¥éŸ³é¢‘æ•°æ®
                for (sample in recordedAudioData) {
                    audioFileWriter!!.write(sample.toInt() and 0xFF)
                    audioFileWriter!!.write((sample.toInt() shr 8) and 0xFF)
                }
                
                audioFileWriter!!.close()
                
                // æ›´æ–°WAVæ–‡ä»¶å¤´
                val dataSize = recordedAudioData.size * 2
                val randomAccessFile = RandomAccessFile(currentAudioFile!!, "rw")
                
                // æ›´æ–°æ–‡ä»¶å¤§å°
                randomAccessFile.seek(4)
                randomAccessFile.write(intToByteArray(dataSize + 36))
                
                // æ›´æ–°æ•°æ®å¤§å°
                randomAccessFile.seek(40)
                randomAccessFile.write(intToByteArray(dataSize))
                
                randomAccessFile.close()
                
                Log.i(TAG, "ğŸµ Audio file saved: ${currentAudioFile!!.absolutePath}")
                Log.i(TAG, "ğŸµ File size: ${currentAudioFile!!.length()} bytes")
            }
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Failed to finalize audio file: ${e.message}")
        } finally {
            audioFileWriter = null
            currentAudioFile = null
            recordedAudioData.clear()
        }
    }

    // ğŸµ è·å–æœ€åå½•éŸ³æ–‡ä»¶è·¯å¾„
    fun getLastRecordingPath(): String? {
        return currentAudioFile?.absolutePath
    }

    fun destroy() {
        try {
            stopRecognition()
            
            audioRecord?.release()
            vad?.release()
            offlineRecognizer?.release()
            
            audioRecord = null
            vad = null
            offlineRecognizer = null
            
            audioBuffer.clear()
            resultList.clear()
            
            Log.i(TAG, "ğŸ—‘ï¸ Resources destroyed")
        } catch (e: Exception) {
            Log.e(TAG, "Error during destroy: ${e.message}")
        }
    }

    // ğŸ¯ å…¼å®¹åŸæœ‰æ¥å£
    fun processAudio(audioData: FloatArray, sampleRate: Int): String {
        // ç”±äºç°åœ¨ä½¿ç”¨åŸç”ŸAudioRecordï¼Œè¿™ä¸ªæ–¹æ³•ä¸»è¦ç”¨äºè·å–å½“å‰ç»“æœ
        return getCurrentText()
    }

    private fun getCurrentText(): String {
        val displayText = StringBuilder()
        
        resultList.forEachIndexed { index, text ->
            displayText.append("${index + 1}: $text")
            if (index < resultList.size - 1) {
                displayText.append("\n")
            }
        }
        
        // ğŸ”§ åªåœ¨æœ‰æœ‰æ•ˆè¯†åˆ«ç»“æœæ—¶æ˜¾ç¤ºå½“å‰éƒ¨åˆ†æ–‡æœ¬
        if (currentPartialText.isNotEmpty() && isValidRecognitionText(currentPartialText)) {
            if (displayText.isNotEmpty()) {
                displayText.append("\n")
            }
            displayText.append("${resultList.size + 1}: $currentPartialText")
        }
        
        return displayText.toString()
    }

    fun finishRecognition(): String {
        return try {
            stopRecognition()
            val finalText = getCurrentText()
            Log.i(TAG, "Recognition finished with result: $finalText")
            finalText
        } catch (e: Exception) {
            Log.e(TAG, "Failed to finish recognition: ${e.message}")
            ""
        }
    }
} 