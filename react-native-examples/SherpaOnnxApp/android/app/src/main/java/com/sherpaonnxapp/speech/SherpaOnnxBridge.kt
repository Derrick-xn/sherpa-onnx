package com.sherpaonnxapp.speech

import android.content.res.AssetManager
import android.util.Log
import android.media.AudioRecord
import android.media.MediaRecorder
import android.media.AudioFormat
import com.k2fsa.sherpa.onnx.*
import java.util.concurrent.atomic.AtomicBoolean
import kotlinx.coroutines.*
import kotlinx.coroutines.channels.Channel
import kotlinx.coroutines.channels.Channel.Factory.UNLIMITED

// ğŸš€ å®Œå…¨å¤åˆ»åç¼–è¯‘APKçš„åŒåç¨‹æ¶æ„
class SherpaOnnxBridge(private val assetManager: AssetManager) {
    private var offlineRecognizer: OfflineRecognizer? = null
    private var vad: Vad? = null
    private val TAG = "SherpaOnnxBridge"
    
    // ğŸ¯ åç¼–è¯‘APKçš„æ ¸å¿ƒå‚æ•°
    private val sampleRate = 16000
    private val windowSize = 6400 // 0.4ç§’çª—å£ï¼ˆå®Œå…¨å¤åˆ»ï¼‰
    private val chunkSize = 1600   // 0.1ç§’éŸ³é¢‘å—ï¼ˆå®Œå…¨å¤åˆ»ï¼‰
    
    // ğŸ¯ åŒåç¨‹é€šä¿¡Channelï¼ˆå¤åˆ»åç¼–è¯‘APKï¼‰
    private val samplesChannel = Channel<FloatArray>(UNLIMITED)
    
    // ğŸ¯ åç¼–è¯‘APKçš„çŠ¶æ€å˜é‡ï¼ˆå®Œå…¨å¯¹åº”ï¼‰
    private val audioBuffer = mutableListOf<Float>()
    private var lastText = ""
    private var offset = 0
    private var isSpeechStarted = false
    private var startTime = 0L
    private var added = false
    
    // ğŸ¯ åŸç”ŸAudioRecordï¼ˆå¤åˆ»åç¼–è¯‘APKï¼‰
    private var audioRecord: AudioRecord? = null
    private val isRecording = AtomicBoolean(false)
    private var recordingJob: Job? = null
    private var processingJob: Job? = null
    
    // ğŸ¯ ç»“æœç®¡ç†
    private val resultList = mutableListOf<String>()
    private var currentPartialText = ""
    private var onResultCallback: ((String) -> Unit)? = null

    companion object {
        init {
            try {
                System.loadLibrary("sherpa-onnx-jni")
                Log.i("SherpaOnnxBridge", "Successfully loaded sherpa-onnx-jni library")
            } catch (e: UnsatisfiedLinkError) {
                Log.e("SherpaOnnxBridge", "Failed to load sherpa-onnx-jni library: ${e.message}")
            }
        }
    }

    fun initialize(): Boolean {
        return try {
            Log.i(TAG, "ğŸš€ Initializing SenseVoice + VAD recognizer (APK-style)")
            
            // åˆå§‹åŒ–åŸç”ŸAudioRecordï¼ˆå¤åˆ»åç¼–è¯‘APKï¼‰
            initializeAudioRecord()
            
            // åˆå§‹åŒ–VAD
            vad = createVAD()
            
            // åˆå§‹åŒ–SenseVoiceè¯†åˆ«å™¨
            offlineRecognizer = createSenseVoiceRecognizer()
            
            Log.i(TAG, "âœ… SenseVoice + VAD recognizer initialized successfully")
            true
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Failed to initialize recognizer: ${e.message}")
            e.printStackTrace()
            false
        }
    }

    // ğŸ¯ å¤åˆ»åç¼–è¯‘APKçš„AudioRecordåˆå§‹åŒ–
    private fun initializeAudioRecord() {
        val channelConfig = AudioFormat.CHANNEL_IN_MONO
        val audioFormat = AudioFormat.ENCODING_PCM_16BIT
        val minBufferSize = AudioRecord.getMinBufferSize(sampleRate, channelConfig, audioFormat)
        val bufferSize = minBufferSize.coerceAtLeast(chunkSize * 2)
        
        audioRecord = AudioRecord(
            MediaRecorder.AudioSource.MIC,
            sampleRate,
            channelConfig,
            audioFormat,
            bufferSize
        )
        
        Log.i(TAG, "ğŸ™ï¸ AudioRecord initialized: bufferSize=$bufferSize, chunkSize=$chunkSize")
    }

    private fun createVAD(): Vad {
        val sileroVadConfig = SileroVadModelConfig(
            model = "silero_vad.onnx",
            threshold = 0.45f,
            minSilenceDuration = 0.5f,
            minSpeechDuration = 0.25f,
            maxSpeechDuration = 8.0f,
            windowSize = 512
        )
        
        val vadConfig = VadModelConfig(
            sileroVadModelConfig = sileroVadConfig,
            sampleRate = sampleRate,
            numThreads = 1,
            provider = "cpu",
            debug = false
        )
        
        return Vad(assetManager, vadConfig)
    }

    private fun createSenseVoiceRecognizer(): OfflineRecognizer {
        val senseVoiceConfig = OfflineSenseVoiceModelConfig(
            model = "models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx",
            language = "",  // ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹è¯­è¨€
            useInverseTextNormalization = true
        )
        
        val modelConfig = OfflineModelConfig(
            senseVoice = senseVoiceConfig,
            tokens = "models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt",
            modelType = "sense_voice",
            numThreads = 2,  // ğŸ¯ ä¸¥æ ¼å¤åˆ»ï¼šå¼ºåˆ¶è®¾ç½®ä¸º2çº¿ç¨‹
            debug = false,
            provider = "cpu"
        )
        
        val recognizerConfig = OfflineRecognizerConfig(
            featConfig = getFeatureConfig(sampleRate = sampleRate, featureDim = 80),
            modelConfig = modelConfig,
            decodingMethod = "greedy_search",
            maxActivePaths = 4
        )
        
        return OfflineRecognizer(assetManager, recognizerConfig)
    }

    // ğŸ¯ å¤åˆ»åç¼–è¯‘APKçš„åŒåç¨‹å¯åŠ¨
    fun startRecognition(): Boolean {
        return try {
            if (offlineRecognizer == null || vad == null || audioRecord == null) {
                initialize()
            }
            
            // é‡ç½®çŠ¶æ€ï¼ˆå¤åˆ»åç¼–è¯‘APKï¼‰
            audioBuffer.clear()
            resultList.clear()
            lastText = ""
            offset = 0
            isSpeechStarted = false
            startTime = System.currentTimeMillis()
            added = false
            currentPartialText = ""
            
            isRecording.set(true)
            
            // ğŸš€ å¯åŠ¨åŒåç¨‹ï¼ˆå®Œå…¨å¤åˆ»åç¼–è¯‘APKæ¶æ„ï¼‰
            startAnonymousClass1() // éŸ³é¢‘å½•åˆ¶åç¨‹
            startAnonymousClass2() // éŸ³é¢‘å¤„ç†åç¨‹
            
            Log.i(TAG, "ğŸ™ï¸ sherpa-onnx-sim-asr: Started dual-coroutine recording")
            true
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Failed to start recognition: ${e.message}")
            false
        }
    }

    // ğŸ¯ AnonymousClass1: éŸ³é¢‘å½•åˆ¶åç¨‹ï¼ˆå®Œå…¨å¤åˆ»åç¼–è¯‘APKï¼‰
    private fun startAnonymousClass1() {
        recordingJob = CoroutineScope(Dispatchers.IO).launch {
            Log.i(TAG, "ğŸ™ï¸ sherpa-onnx-sim-asr: processing samples")
            
            // å®Œå…¨å¤åˆ»åç¼–è¯‘APKï¼š16000 * 0.1 = 1600æ ·æœ¬
            val bufferSize = (sampleRate * 0.1).toInt()
            val shortBuffer = ShortArray(bufferSize)
            
            audioRecord?.startRecording()
            
            while (isRecording.get()) {
                val bytesRead = audioRecord?.read(shortBuffer, 0, shortBuffer.size) ?: -1
                
                if (bytesRead > 0) {
                    // ğŸ¯ å®Œå…¨å¤åˆ»åç¼–è¯‘APKçš„è½¬æ¢é€»è¾‘
                    val floatSamples = FloatArray(bytesRead)
                    for (i in 0 until bytesRead) {
                        val shortSample = shortBuffer[i]
                        floatSamples[i] = shortSample.toFloat() / 32768.0f // å¤åˆ»APKè½¬æ¢
                    }
                    
                    // é€šè¿‡Channelå‘é€ï¼ˆå¤åˆ»åç¼–è¯‘APKï¼‰
                    samplesChannel.trySend(floatSamples)
                }
            }
            
            // å‘é€ç©ºæ•°ç»„ç»“æŸä¿¡å·ï¼ˆå¤åˆ»åç¼–è¯‘APKï¼‰
            samplesChannel.trySend(FloatArray(0))
        }
    }

    // ğŸ¯ AnonymousClass2: éŸ³é¢‘å¤„ç†åç¨‹ï¼ˆå®Œå…¨å¤åˆ»åç¼–è¯‘APKï¼‰
    private fun startAnonymousClass2() {
        processingJob = CoroutineScope(Dispatchers.Default).launch {
            Log.i(TAG, "ğŸ”„ sherpa-onnx-sim-asr: å¯åŠ¨AnonymousClass2")
            
            // å¤åˆ»åç¼–è¯‘APKçš„å¾ªç¯å¤„ç†
            for (samples in samplesChannel) {
                if (samples.isEmpty()) break // ç»“æŸä¿¡å·
                
                // ğŸ¯ å®Œå…¨å¤åˆ»åç¼–è¯‘APKçš„å¤„ç†é€»è¾‘
                processAnonymousClass2Logic(samples)
            }
        }
    }

    // ğŸ¯ æ ¸å¿ƒï¼šAnonymousClass2çš„å¤„ç†é€»è¾‘ï¼ˆå®Œå…¨å¤åˆ»åç¼–è¯‘APKï¼‰
    private suspend fun processAnonymousClass2Logic(floatSamples: FloatArray) {
        try {
            audioBuffer.addAll(floatSamples.toList())
            
            // ğŸ¯ VADå¤„ç† - ä¸»è¦ç”¨äºæ£€æµ‹å®Œæ•´è¯­éŸ³æ®µ
            if (audioBuffer.size >= chunkSize) {
                processVADWithBuffer()
            }
            
            // ğŸ¯ æ»‘åŠ¨çª—å£æœºåˆ¶ï¼ˆå¤åˆ»åç¼–è¯‘APKé€»è¾‘ï¼‰
            if (audioBuffer.size >= windowSize * 3) {
                val removeCount = audioBuffer.size - windowSize
                repeat(removeCount) { audioBuffer.removeAt(0) }
                offset += removeCount
            }
            
            // ğŸ¯ ä¼˜åŒ–çš„å®æ—¶è¯†åˆ« - å‡å°‘é¢‘ç‡é¿å…è·³åŠ¨ï¼ˆå¤åˆ»APKç®—æ³•ï¼‰
            if (audioBuffer.size >= windowSize && audioBuffer.size % 800 == 0) {
                performStableRealtimeRecognition()
            }
        } catch (e: Exception) {
            Log.e(TAG, "AnonymousClass2å¤„ç†é”™è¯¯: ${e.message}")
        }
    }

    private fun processVADWithBuffer() {
        try {
            val vadChunkSize = chunkSize
            if (audioBuffer.size >= vadChunkSize) {
                val vadData = FloatArray(vadChunkSize)
                val startIndex = kotlin.math.max(0, audioBuffer.size - vadChunkSize)
                
                for (i in 0 until vadChunkSize) {
                    vadData[i] = audioBuffer[startIndex + i]
                }
                
                vad?.acceptWaveform(vadData)
                
                // ğŸ¯ å¤„ç†VADæ£€æµ‹åˆ°çš„å®Œæ•´è¯­éŸ³æ®µ
                while (vad?.empty() == false) {
                    val speechSegment = vad?.front()
                    vad?.pop()
                    
                    if (speechSegment != null) {
                        processFinalSpeechSegment(speechSegment)
                    }
                }
            }
        } catch (e: Exception) {
            Log.e(TAG, "VAD processing error: ${e.message}")
        }
    }

    private fun processFinalSpeechSegment(speechSegment: SpeechSegment) {
        try {
            val stream = offlineRecognizer?.createStream()
            stream?.acceptWaveform(speechSegment.samples, sampleRate)
            
            offlineRecognizer?.decode(stream!!)
            val result = offlineRecognizer?.getResult(stream!!)
            val text = result?.text?.trim() ?: ""
            
            if (text.isNotEmpty() && text.length > 1) {
                // ğŸ¯ æ·»åŠ åˆ°ç»“æœåˆ—è¡¨ï¼ˆå¤åˆ»åç¼–è¯‘APKï¼‰
                resultList.add(text)
                updateResults()
                Log.i(TAG, "âœ… Speech segment recognized: $text")
            }
            
            stream?.release()
        } catch (e: Exception) {
            Log.e(TAG, "Error processing speech segment: ${e.message}")
        }
    }

    private fun performStableRealtimeRecognition() {
        try {
            if (audioBuffer.size < windowSize) return
            
            val windowStart = kotlin.math.max(0, audioBuffer.size - windowSize)
            val windowAudio = FloatArray(windowSize)
            
            for (i in 0 until windowSize) {
                windowAudio[i] = audioBuffer[windowStart + i]
            }
            
            val stream = offlineRecognizer?.createStream()
            stream?.acceptWaveform(windowAudio, sampleRate)
            
            offlineRecognizer?.decode(stream!!)
            val result = offlineRecognizer?.getResult(stream!!)
            val text = result?.text?.trim() ?: ""
            
            // ğŸ¯ ç¨³å®šæ€§æ£€æŸ¥ - å‡å°‘æ–‡å­—è·³åŠ¨
            if (text.isNotEmpty() && text.length > 1 && text != lastText) {
                lastText = text
                currentPartialText = text
                updateResults()
            }
            
            stream?.release()
        } catch (e: Exception) {
            Log.e(TAG, "Error in realtime recognition: ${e.message}")
        }
    }

    // ğŸ¯ æ›´æ–°ç»“æœæ˜¾ç¤ºï¼ˆå¤åˆ»åç¼–è¯‘APKæ ¼å¼ï¼‰
    private fun updateResults() {
        val displayText = StringBuilder()
        
        // æ·»åŠ å·²å®Œæˆçš„è¯†åˆ«ç»“æœ
        resultList.forEachIndexed { index, text ->
            displayText.append("${index + 1}: $text")
            if (index < resultList.size - 1) {
                displayText.append("\n")
            }
        }
        
        // æ·»åŠ å½“å‰éƒ¨åˆ†è¯†åˆ«ç»“æœ
        if (currentPartialText.isNotEmpty()) {
            if (displayText.isNotEmpty()) {
                displayText.append("\n")
            }
            displayText.append("${resultList.size + 1}: $currentPartialText")
        }
        
        // å›è°ƒæ›´æ–°UIï¼ˆæ¨¡æ‹Ÿåç¼–è¯‘APKçš„è‡ªåŠ¨æ»šåŠ¨æ•ˆæœï¼‰
        onResultCallback?.invoke(displayText.toString())
    }

    fun setResultCallback(callback: (String) -> Unit) {
        onResultCallback = callback
    }

    fun stopRecognition(): Boolean {
        return try {
            isRecording.set(false)
            
            // åœæ­¢å½•éŸ³
            audioRecord?.stop()
            
            // å–æ¶ˆåç¨‹
            recordingJob?.cancel()
            processingJob?.cancel()
            
            Log.i(TAG, "ğŸ›‘ Recognition stopped")
            true
        } catch (e: Exception) {
            Log.e(TAG, "âŒ Failed to stop recognition: ${e.message}")
            false
        }
    }

    fun destroy() {
        try {
            stopRecognition()
            
            audioRecord?.release()
            vad?.release()
            offlineRecognizer?.release()
            
            audioRecord = null
            vad = null
            offlineRecognizer = null
            
            audioBuffer.clear()
            resultList.clear()
            
            Log.i(TAG, "ğŸ—‘ï¸ Resources destroyed")
        } catch (e: Exception) {
            Log.e(TAG, "Error during destroy: ${e.message}")
        }
    }

    // ğŸ¯ å…¼å®¹åŸæœ‰æ¥å£
    fun processAudio(audioData: FloatArray, sampleRate: Int): String {
        // ç”±äºç°åœ¨ä½¿ç”¨åŸç”ŸAudioRecordï¼Œè¿™ä¸ªæ–¹æ³•ä¸»è¦ç”¨äºè·å–å½“å‰ç»“æœ
        return getCurrentText()
    }

    private fun getCurrentText(): String {
        val displayText = StringBuilder()
        
        resultList.forEachIndexed { index, text ->
            displayText.append("${index + 1}: $text")
            if (index < resultList.size - 1) {
                displayText.append("\n")
            }
        }
        
        if (currentPartialText.isNotEmpty()) {
            if (displayText.isNotEmpty()) {
                displayText.append("\n")
            }
            displayText.append("${resultList.size + 1}: $currentPartialText")
        }
        
        return displayText.toString()
    }

    fun finishRecognition(): String {
        return try {
            stopRecognition()
            val finalText = getCurrentText()
            Log.i(TAG, "Recognition finished with result: $finalText")
            finalText
        } catch (e: Exception) {
            Log.e(TAG, "Failed to finish recognition: ${e.message}")
            ""
        }
    }
} 