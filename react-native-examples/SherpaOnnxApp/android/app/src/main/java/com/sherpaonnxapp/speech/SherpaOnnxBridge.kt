package com.sherpaonnxapp.speech

import android.content.res.AssetManager
import android.util.Log
import com.k2fsa.sherpa.onnx.*
import java.util.concurrent.BlockingQueue
import java.util.concurrent.LinkedBlockingQueue
import java.util.concurrent.atomic.AtomicBoolean
import kotlin.math.max

class SherpaOnnxBridge(private val assetManager: AssetManager) {
    private var offlineRecognizer: OfflineRecognizer? = null
    private var vad: Vad? = null
    private val TAG = "SherpaOnnxBridge"
    
    // éŸ³é¢‘å¤„ç†ç›¸å…³
    private val sampleRate = 16000
    private val windowSize = 6400 // 0.4ç§’çª—å£
    private val audioBuffer = mutableListOf<Float>()
    private val isProcessing = AtomicBoolean(false)
    private val audioQueue: BlockingQueue<FloatArray> = LinkedBlockingQueue()
    
    // è¯­éŸ³æ£€æµ‹çŠ¶æ€
    private var isSpeechStarted = false
    private var speechSegmentStart = 0
    private var resultList = mutableListOf<String>()
    
    // å®æ—¶è¯†åˆ«çŠ¶æ€
    private var lastStableText = ""
    private var stableCounter = 0
    private var currentPartialText = ""
    
    // ğŸ”§ æ–°å¢ï¼šFlutteré£æ ¼çš„é‡å¤æ£€æµ‹æœºåˆ¶
    private var lastProcessedText = ""
    private var duplicateCounter = 0
    private val maxDuplicates = 3

    companion object {
        init {
            try {
                System.loadLibrary("sherpa-onnx-jni")
                Log.i("SherpaOnnxBridge", "Successfully loaded sherpa-onnx-jni library")
            } catch (e: UnsatisfiedLinkError) {
                Log.e("SherpaOnnxBridge", "Failed to load sherpa-onnx-jni library: ${e.message}")
            }
        }
    }

    fun initialize(): Boolean {
        return try {
            Log.i(TAG, "Initializing SenseVoice + VAD recognizer")
            
            // åˆå§‹åŒ–VAD
            vad = createVAD()
            
            // åˆå§‹åŒ–SenseVoiceè¯†åˆ«å™¨
            offlineRecognizer = createSenseVoiceRecognizer()
            
            Log.i(TAG, "SenseVoice + VAD recognizer initialized successfully")
            true
        } catch (e: Exception) {
            Log.e(TAG, "Failed to initialize recognizer: ${e.message}")
            e.printStackTrace()
            false
        }
    }

    private fun createVAD(): Vad {
        // ä½¿ç”¨ç›´æ¥æ„é€ å‡½æ•°åˆ›å»ºVADé…ç½®
        val sileroVadConfig = SileroVadModelConfig(
            model = "silero_vad.onnx",
            threshold = 0.45f,
            minSilenceDuration = 0.5f,
            minSpeechDuration = 0.25f,
            maxSpeechDuration = 8.0f,
            windowSize = 512
        )
        
        val vadConfig = VadModelConfig(
            sileroVadModelConfig = sileroVadConfig,
            sampleRate = sampleRate,
            numThreads = 1,
            provider = "cpu",
            debug = false
        )
        
        return Vad(assetManager, vadConfig)
    }

    private fun createSenseVoiceRecognizer(): OfflineRecognizer {
        // ä½¿ç”¨ç›´æ¥æ„é€ å‡½æ•°åˆ›å»ºSenseVoiceé…ç½®
        val senseVoiceConfig = OfflineSenseVoiceModelConfig(
            model = "models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx",
            language = "",  // ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹è¯­è¨€
            useInverseTextNormalization = true
        )
        
        val modelConfig = OfflineModelConfig(
            senseVoice = senseVoiceConfig,
            tokens = "models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt",
            modelType = "sense_voice",
            numThreads = 2,  // ä¸¥æ ¼å¤åˆ»ï¼šå¼ºåˆ¶è®¾ç½®ä¸º2çº¿ç¨‹
            debug = false,
            provider = "cpu"
        )
        
        val recognizerConfig = OfflineRecognizerConfig(
            featConfig = getFeatureConfig(sampleRate = sampleRate, featureDim = 80),
            modelConfig = modelConfig,
            decodingMethod = "greedy_search",
            maxActivePaths = 4
        )
        
        return OfflineRecognizer(assetManager, recognizerConfig)
    }

    fun startRecognition(): Boolean {
        return try {
            if (offlineRecognizer == null || vad == null) {
                initialize()
            }
            
            // æ¸…ç©ºç¼“å†²åŒºå’ŒçŠ¶æ€
            audioBuffer.clear()
            resultList.clear()
            isSpeechStarted = false
            speechSegmentStart = 0
            lastStableText = ""
            stableCounter = 0
            currentPartialText = ""
            
            Log.i(TAG, "Started SenseVoice recognition")
            true
        } catch (e: Exception) {
            Log.e(TAG, "Failed to start recognition: ${e.message}")
            false
        }
    }

    fun processAudio(audioData: FloatArray, sampleRate: Int): String {
        return try {
            if (isProcessing.get()) {
                return getCurrentText()
            }
            
            isProcessing.set(true)
            
            // ğŸ”§ æ”¹è¿›ï¼šæ·»åŠ éŸ³é¢‘åˆ†å—å¤„ç†ï¼ˆå¤åˆ»Flutteré€»è¾‘ï¼‰
            processAudioInChunks(audioData)
            
            isProcessing.set(false)
            getCurrentText()
        } catch (e: Exception) {
            Log.e(TAG, "Failed to process audio: ${e.message}")
            isProcessing.set(false)
            ""
        }
    }

    // ğŸ”§ æ–°å¢ï¼šæ¨¡ä»¿Flutterçš„éŸ³é¢‘åˆ†å—å¤„ç†
    private fun processAudioInChunks(audioData: FloatArray) {
        val chunkSize = 1600 // 0.1ç§’éŸ³é¢‘å—ï¼Œå®Œå…¨å¤åˆ»Flutter
        
        audioBuffer.addAll(audioData.toList())
        
        // ğŸ¯ ç²¾ç¡®çš„æ»‘åŠ¨çª—å£æœºåˆ¶ï¼ˆå¤åˆ»Flutteré€»è¾‘ï¼‰
        if (audioBuffer.size >= windowSize * 3) {
            val newOffset = audioBuffer.size - windowSize
            val removeCount = audioBuffer.size - windowSize
            repeat(removeCount) { audioBuffer.removeAt(0) }
        }
        
        // ğŸ¯ VADå¤„ç† - ä¸»è¦ç”¨äºæ£€æµ‹å®Œæ•´è¯­éŸ³æ®µ
        if (audioBuffer.size >= chunkSize) {
            processVADWithBuffer()
        }
        
        // ğŸ¯ ä¼˜åŒ–çš„å®æ—¶è¯†åˆ« - å‡å°‘é¢‘ç‡é¿å…è·³åŠ¨ï¼ˆå¤åˆ»Flutterç®—æ³•ï¼‰
        if (audioBuffer.size >= windowSize && audioBuffer.size % 800 == 0) {
            performStableRealtimeRecognition()
        }
    }
    
    // ğŸ”§ æ”¹è¿›ï¼šå¤åˆ»Flutterçš„VADå¤„ç†é€»è¾‘
    private fun processVADWithBuffer() {
        try {
            val vadChunkSize = 1600 // ä¸Flutterä¿æŒä¸€è‡´
            if (audioBuffer.size >= vadChunkSize) {
                val vadData = FloatArray(vadChunkSize)
                val startIndex = kotlin.math.max(0, audioBuffer.size - vadChunkSize)
                
                for (i in 0 until vadChunkSize) {
                    vadData[i] = audioBuffer[startIndex + i]
                }
                
                vad?.acceptWaveform(vadData)
                
                // ğŸ¯ å¤„ç†VADæ£€æµ‹åˆ°çš„å®Œæ•´è¯­éŸ³æ®µ
                while (vad?.empty() == false) {
                    val speechSegment = vad?.front()
                    vad?.pop()
                    
                    if (speechSegment != null) {
                        processFinalSpeechSegment(speechSegment)
                    }
                }
            }
        } catch (e: Exception) {
            Log.e(TAG, "VAD processing error: ${e.message}")
        }
    }

    private fun processFinalSpeechSegment(speechSegment: SpeechSegment) {
        try {
            val stream = offlineRecognizer?.createStream()
            stream?.acceptWaveform(speechSegment.samples, sampleRate)
            
            offlineRecognizer?.decode(stream!!)
            val result = offlineRecognizer?.getResult(stream!!)
            val text = result?.text?.trim() ?: ""
            
            if (text.isNotEmpty() && text.length > 1) {
                // æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                resultList.add(text)
                Log.i(TAG, "Speech segment recognized: $text")
            }
            
            stream?.release()
        } catch (e: Exception) {
            Log.e(TAG, "Error processing speech segment: ${e.message}")
        }
    }

    private fun performRealtimeRecognition() {
        try {
            if (audioBuffer.size < windowSize) return
            
            val windowStart = max(0, audioBuffer.size - windowSize)
            val windowAudio = FloatArray(windowSize)
            
            for (i in 0 until windowSize) {
                windowAudio[i] = audioBuffer[windowStart + i]
            }
            
            val stream = offlineRecognizer?.createStream()
            stream?.acceptWaveform(windowAudio, sampleRate)
            
            offlineRecognizer?.decode(stream!!)
            val result = offlineRecognizer?.getResult(stream!!)
            val text = result?.text?.trim() ?: ""
            
            // ç¨³å®šæ€§æ£€æŸ¥ - å‡å°‘æ–‡å­—è·³åŠ¨
            if (text.isNotEmpty() && text.length > 1) {
                if (text == lastStableText) {
                    stableCounter++
                    if (stableCounter >= 2) {
                        // è¿ç»­2æ¬¡ç›¸åŒæ‰æ›´æ–°
                        currentPartialText = text
                    }
                } else {
                    lastStableText = text
                    stableCounter = 1
                }
            }
            
            stream?.release()
        } catch (e: Exception) {
            Log.e(TAG, "Error in realtime recognition: ${e.message}")
        }
    }

    private fun getCurrentText(): String {
        val displayText = StringBuilder()
        
        // æ·»åŠ å·²å®Œæˆçš„è¯†åˆ«ç»“æœ
        resultList.forEachIndexed { index, text ->
            displayText.append("${index + 1}: $text")
            if (index < resultList.size - 1) {
                displayText.append("\n")
            }
        }
        
        // æ·»åŠ å½“å‰éƒ¨åˆ†è¯†åˆ«ç»“æœ
        if (currentPartialText.isNotEmpty()) {
            if (displayText.isNotEmpty()) {
                displayText.append("\n")
            }
            displayText.append("${resultList.size + 1}: $currentPartialText")
        }
        
        return displayText.toString()
    }

    fun finishRecognition(): String {
        return try {
            // å¤„ç†å‰©ä½™çš„éŸ³é¢‘ç¼“å†²åŒº
            if (audioBuffer.isNotEmpty()) {
                // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ–°çš„éŸ³é¢‘å¤„ç†æ–¹æ³•
                processAudioInChunks(FloatArray(0)) // è§¦å‘æœ€ç»ˆå¤„ç†
            }
            
            val finalText = getCurrentText()
            Log.i(TAG, "Recognition finished with result: $finalText")
            finalText
        } catch (e: Exception) {
            Log.e(TAG, "Failed to finish recognition: ${e.message}")
            ""
        }
    }

    fun destroy() {
        try {
            vad?.release()
            offlineRecognizer?.release()
            vad = null
            offlineRecognizer = null
            audioBuffer.clear()
            resultList.clear()
            Log.i(TAG, "Resources destroyed")
        } catch (e: Exception) {
            Log.e(TAG, "Error during destroy: ${e.message}")
        }
    }
    
    // ğŸ”§ æ–°å¢ï¼šå¤åˆ»Flutterçš„é‡å¤æ£€æµ‹ç®—æ³•
    private fun isResultDuplicate(newResult: String): Boolean {
        if (newResult.isEmpty() || newResult.length <= 1) return true
        
        // 1. å®Œå…¨ç›¸åŒæ£€æµ‹
        if (newResult == lastProcessedText) {
            duplicateCounter++
            return duplicateCounter > maxDuplicates
        }
        
        // 2. é‡å¤å­—ç¬¦æ¨¡å¼æ£€æµ‹ï¼ˆå¦‚"æœäº†æœäº†æœäº†"ï¼‰
        val chars = newResult.toCharArray()
        if (chars.size > 4) {
            val firstChar = chars[0]
            val allSame = chars.all { it == firstChar || it == ' ' }
            if (allSame) {
                Log.w(TAG, "Detected repeated character pattern: $newResult")
                return true
            }
        }
        
        // 3. è¯æ±‡é‡å¤æ£€æµ‹ï¼ˆ>50%é‡å¤ï¼‰
        val words = newResult.split("\\s+".toRegex()).filter { it.isNotEmpty() }
        if (words.size > 2) {
            val uniqueWords = words.toSet()
            if (uniqueWords.size < words.size * 0.5) {
                Log.w(TAG, "Detected word repetition pattern: $newResult")
                return true
            }
        }
        
        // é‡ç½®è®¡æ•°å™¨
        lastProcessedText = newResult
        duplicateCounter = 0
        return false
    }
    
    // ğŸ”§ æ”¹è¿›ï¼šæ›´ç¨³å®šçš„å®æ—¶è¯†åˆ«
    private fun performStableRealtimeRecognition() {
        try {
            if (audioBuffer.size < windowSize) return
            
            val windowStart = max(0, audioBuffer.size - windowSize)
            val windowAudio = FloatArray(windowSize)
            
            for (i in 0 until windowSize) {
                windowAudio[i] = audioBuffer[windowStart + i]
            }
            
            val stream = offlineRecognizer?.createStream()
            stream?.acceptWaveform(windowAudio, sampleRate)
            
            offlineRecognizer?.decode(stream!!)
            val result = offlineRecognizer?.getResult(stream!!)
            val text = result?.text?.trim() ?: ""
            
            // ğŸ¯ é‡å¤æ£€æµ‹ + ç¨³å®šæ€§æ£€æŸ¥
            if (text.isNotEmpty() && !isResultDuplicate(text)) {
                if (text == lastStableText) {
                    stableCounter++
                    if (stableCounter >= 2) {
                        // è¿ç»­2æ¬¡ç›¸åŒä¸”éé‡å¤æ‰æ›´æ–°
                        updateRealtimeTextStable(text)
                    }
                } else {
                    // ä¸Šä¸€ä¸ªç»“æœç¨³å®šåæ‰å¯èƒ½æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                    if (stableCounter >= 2 && lastStableText.isNotEmpty()) {
                        // è¿™é‡Œå¯ä»¥è€ƒè™‘æ˜¯å¦éœ€è¦å°†ç¨³å®šçš„ç»“æœæ·»åŠ åˆ°æœ€ç»ˆåˆ—è¡¨
                        Log.d(TAG, "Previous stable result: $lastStableText")
                    }
                    lastStableText = text
                    stableCounter = 1
                }
            }
            
            stream?.release()
        } catch (e: Exception) {
            Log.e(TAG, "Error in stable realtime recognition: ${e.message}")
        }
    }
    
    // ğŸ”§ æ–°å¢ï¼šç¨³å®šçš„å®æ—¶æ–‡æœ¬æ›´æ–°
    private fun updateRealtimeTextStable(text: String) {
        if (text == currentPartialText) return // é¿å…é‡å¤æ›´æ–°
        
        currentPartialText = text
        Log.d(TAG, "Updated stable partial text: $text")
    }
} 