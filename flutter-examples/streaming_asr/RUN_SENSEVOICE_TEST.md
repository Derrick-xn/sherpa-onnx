# SenseVoice 模拟流式识别测试指南

## 🚀 快速开始

基于反编译APK的技术分析，我们成功实现了SenseVoice多语言模拟流式识别！

### ✅ 已完成功能
- ✅ SenseVoice多语言模型集成（中英日韩粤）
- ✅ Silero VAD语音活动检测
- ✅ 模拟流式识别实现
- ✅ 美观的双模式UI界面
- ✅ 音频缓存和实时处理

## 📱 运行测试

### 1. 安装依赖
```bash
cd flutter-examples/streaming_asr
flutter pub get
```

### 2. 启动应用
```bash
flutter run
```

### 3. 使用说明
1. **选择识别模式**：
   - 绿色按钮：传统流式识别（Zipformer模型）
   - 橙色按钮：SenseVoice多语言识别 ⭐（推荐）

2. **测试SenseVoice**：
   - 点击"SenseVoice多语言识别"
   - 等待模型初始化（显示✅已初始化）
   - 点击麦克风开始录音
   - 尝试说中文、英文或其他支持的语言

## 🎯 测试重点

### 多语言混合测试
尝试以下混合语言测试：
```
中英混合：我想要一杯coffee
中日混合：今天はいい天気ですね，很舒服
英韩混合：Hello, 안녕하세요
粤语测试：你好点呀
```

### 语音活动检测测试
- 说话时应该实时显示识别结果
- 停顿时VAD会自动分段处理
- 连续对话会按段落显示

## 🔧 技术架构

### 核心组件
```
OfflineRecognizer (SenseVoice) + VAD (Silero) + 音频处理
= 模拟流式识别体验
```

### 处理流程
```
音频采集 → 缓存 → VAD检测 → 语音段提取 → SenseVoice识别 → 结果显示
```

## 🐛 故障排除

### 常见问题
1. **初始化失败**：检查模型文件是否正确复制到assets/
2. **录音权限**：确保已授予麦克风权限
3. **识别无结果**：确保VAD正确检测到语音活动

### 调试信息
查看Flutter控制台输出：
- `SenseVoice识别器和VAD初始化成功`
- `处理音频失败: xxx` - 查看具体错误信息

## 📊 性能表现

### 预期指标
- **模型大小**：约230MB（SenseVoice + VAD）
- **内存占用**：约200-300MB
- **识别延迟**：100-500ms（取决于语音段长度）
- **准确率**：多语言混合场景下优于传统模型

## 🎉 成功验证后的下一步

### 迁移到RN的准备工作
1. ✅ **技术验证**：Flutter实现证明了方案可行性
2. 🔄 **RN桥接**：基于现有react-native-examples增强
3. 🔄 **原生模块**：扩展SherpaOnnxModule支持SenseVoice
4. 🔄 **JS接口**：封装简洁的RN语音识别接口

### 推荐路径
```
Flutter验证 → RN桥接增强 → 生产环境部署
```

## 📈 相比反编译APK的优势

1. **真正的Flutter实现**：非反向工程，代码清晰可维护
2. **配置灵活**：可调整VAD参数、识别配置等
3. **界面自定义**：完全控制UI/UX体验
4. **跨平台支持**：同时支持iOS和Android
5. **易于集成**：可直接集成到现有项目

## 🎯 测试检查清单

- [ ] 应用正常启动
- [ ] 两种模式都可选择
- [ ] SenseVoice模式初始化成功
- [ ] 中文识别准确
- [ ] 英文识别准确
- [ ] 中英混合识别正常
- [ ] 日文/韩文/粤语识别（如果测试环境支持）
- [ ] VAD正确分段
- [ ] 录音开始/停止正常
- [ ] 没有明显内存泄漏

测试完成后，我们就可以开始RN的迁移工作了！ 🚀 